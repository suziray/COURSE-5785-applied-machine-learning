{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "import copy\n",
    "from sklearn import linear_model\n",
    "from nltk.stem.arlstem import ARLSTem\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from operator import itemgetter, attrgetter\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from matplotlib import pylab as plt\n",
    "\n",
    "current_location = os.getcwd()\n",
    "type(current_location)\n",
    "amazon_location = current_location+\"/sentiment labelled sentences/amazon_cells_labelled.txt\"\n",
    "yelp_location = current_location+\"/sentiment labelled sentences/yelp_labelled.txt\"\n",
    "imbd_location = current_location+\"/sentiment labelled sentences/imdb_labelled.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n"
     ]
    }
   ],
   "source": [
    "amazon_data = pd.read_table(amazon_location,header = None)\n",
    "amazon_lable = amazon_data.iloc[:,1]\n",
    "amazon_positive_ratio = float(np.count_nonzero(amazon_lable.values))/amazon_lable.values.size\n",
    "print amazon_positive_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n"
     ]
    }
   ],
   "source": [
    "yelp_data = pd.read_table(yelp_location,header = None)\n",
    "yelp_lable = yelp_data.iloc[:,1]\n",
    "yelp_positive_ratio = float(np.count_nonzero(yelp_lable.values))/yelp_lable.values.size\n",
    "print yelp_positive_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n"
     ]
    }
   ],
   "source": [
    "imbd_data = pd.read_table(imbd_location,header = None,quoting = 3)\n",
    "imbd_lable = imbd_data.iloc[:,1]\n",
    "imbd_positive_ratio = float(np.count_nonzero(imbd_lable.values))/imbd_lable.values.size\n",
    "print imbd_positive_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def deleteStemWords(DF):\n",
    "    DF.iloc[:,0] = DF.iloc[:,0].str.lower()\n",
    "    for i in range(0,1000):\n",
    "        DF.iloc[i,0] = ' '+DF.iloc[i,0]\n",
    "    for c in string.punctuation:  \n",
    "        if c == '!':\n",
    "            DF.iloc[:,0] = DF.iloc[:,0].str.replace(c,' !')\n",
    "        elif c == '?':\n",
    "            DF.iloc[:,0] = DF.iloc[:,0].str.replace(c,' ?')\n",
    "        else:\n",
    "            DF.iloc[:,0] = DF.iloc[:,0].str.replace(c,'')\n",
    "    DF.iloc[:,0] = DF.iloc[:,0].str.split()\n",
    "    lemmatizer=WordNetLemmatizer()\n",
    "    for i in range(0,1000):\n",
    "        for j in range(0,len(DF.iloc[i,0])):\n",
    "            if str.isalpha(DF.iloc[i,0][j]):\n",
    "                DF.iloc[i,0][j] = lemmatizer.lemmatize(DF.iloc[i,0][j],pos = 'v')\n",
    "                DF.iloc[i,0][j] = lemmatizer.lemmatize(DF.iloc[i,0][j],pos = 'n')\n",
    "                DF.iloc[i,0][j] = lemmatizer.lemmatize(DF.iloc[i,0][j],pos = 'a')\n",
    "            if type(DF.iloc[i,0][j]) == unicode:\n",
    "                DF.iloc[i,0][j] = DF.iloc[i,0][j].encode(\"ascii\")\n",
    "    return DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon_data = deleteStemWords(amazon_data)\n",
    "yelp_data = deleteStemWords(yelp_data)\n",
    "imbd_data = deleteStemWords(imbd_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trainTest(DF):\n",
    "    DF.iloc[:,0]\n",
    "    DF_train = []\n",
    "    DF_test = []\n",
    "    positive_flag = 0\n",
    "    negetive_flag = 0\n",
    "    for i in range(0,1000):\n",
    "        if positive_flag < 400 or negetive_flag < 400 :\n",
    "            if DF.loc[i,1] == 0 and negetive_flag <400:\n",
    "                negetive_flag += 1 \n",
    "                DF_train.append(list(DF.loc[i,:]))\n",
    "            elif DF.loc[i,1] == 1 and positive_flag <400:\n",
    "                positive_flag += 1   \n",
    "                DF_train.append(list(DF.loc[i,:]))\n",
    "            else:\n",
    "                DF_test.append(list(DF.loc[i,:]))\n",
    "        else:\n",
    "            DF_test.append(list(DF.loc[i,:]))\n",
    "    return(DF_train,DF_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "amazon_train,amazon_test = trainTest(amazon_data)\n",
    "yelp_train,yelp_test = trainTest(yelp_data)\n",
    "imbd_train,imbd_test = trainTest(imbd_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_train = []\n",
    "all_train.extend(amazon_train)\n",
    "all_train.extend(yelp_train)\n",
    "all_train.extend(imbd_train)\n",
    "all_test = []\n",
    "all_test.extend(amazon_test)\n",
    "all_test.extend(yelp_test)\n",
    "all_test.extend(imbd_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_lable = []\n",
    "for i in range(0,len(all_train)):\n",
    "    train_lable.append(all_train[i][1])\n",
    "test_lable = []\n",
    "for i in range(0,len(all_test)):\n",
    "    test_lable.append(all_test[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def creatDic(DF_train):\n",
    "    DF_dic = {}\n",
    "    for i in range(0,800):\n",
    "        for j in range(0,len(DF_train[i][0])):\n",
    "            if DF_dic.get(DF_train[i][0][j]) == None:\n",
    "                DF_dic[DF_train[i][0][j]] = 0\n",
    "    return DF_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_dic = creatDic(all_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getFeatures(words_set,dic,gram):\n",
    "    if (gram != 1) and (gram != 2):\n",
    "        return('wrong gram')\n",
    "    feature_matrix = [[None]*len(dic)]*len(words_set)\n",
    "    for i in range(0,len(words_set)):\n",
    "        dic_copy = copy.deepcopy(dic)\n",
    "        feature_matrix[i] = featureVecter(dic_copy,words_set[i][0],gram)\n",
    "    return feature_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def featureVecter(DF_dic,review,gram):\n",
    "    if gram == 1:\n",
    "        for i in range(0,len(review)):\n",
    "            if DF_dic.get(review[i]) != None:\n",
    "                DF_dic[review[i]] = DF_dic.get(review[i]) + 1\n",
    "    elif gram == 2:\n",
    "        if len(review[0])<2:\n",
    "            if DF_dic.get(review[0]) != None:\n",
    "                DF_dic[review[0]] = DF_dic.get(review[0]) + 1\n",
    "        else:\n",
    "            for i in range(0,len(review)-1):\n",
    "                if DF_dic.get(review[i]+review[i+1]) != None:\n",
    "                    DF_dic[review[i]+review[i+1]] = DF_dic.get(review[i]+review[i+1]) + 1\n",
    "    return DF_dic.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_features = getFeatures(all_train,all_dic,1)\n",
    "test_features = getFeatures(all_test,all_dic,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nZhz8ZmaZcfCbmWXGwW9mlpn/B4pabIV6ORFEAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a22121250>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.set_printoptions(threshold='nan')\n",
    "plt.plot(train_features[3],'.r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalizeFeatures(features):\n",
    "    for i in range(0,len(features)):\n",
    "        if sum(features[i])!=0:\n",
    "            features[i] = np.array(features[i])/float(sum(features[i]))\n",
    "        else:\n",
    "            features[i] = np.array(features[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "normalizeFeatures(test_features)\n",
    "normalizeFeatures(train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lrImplement(train_features,train_lable,test_features,test_lable):\n",
    "    lr = linear_model.LogisticRegression(multi_class = 'ovr')\n",
    "    lr.fit(train_features,train_lable)\n",
    "    lr_test_pre = lr.predict(test_features).astype(int)\n",
    "    lr_score = lr.score(test_features,test_lable)\n",
    "    lr_confusion_matrix = confusionMatrix(lr_test_pre,test_lable)\n",
    "    return lr_score,lr_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gnbImplement(train_features,train_lable,test_features,test_lable):\n",
    "    gnb = GaussianNB()\n",
    "    gnb_test_pre = gnb.fit(train_features,train_lable).predict(test_features)\n",
    "    gnb_score = gnb.fit(train_features,train_lable).score(test_features,test_lable)\n",
    "    gnb_confusion_matrix = confusionMatrix(gnb_test_pre,test_lable)\n",
    "    return gnb_score,gnb_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def confusionMatrix(test_pre,test_lable):\n",
    "    confusion_matrix = [[0 for i in range(2)] for i in range(2)] \n",
    "    for i in range(0,600):\n",
    "        if test_pre[i] == test_lable[i]:\n",
    "            if test_pre[i] == 1:\n",
    "                confusion_matrix[0][0] = confusion_matrix[0][0] + 1        #TP\n",
    "            else:\n",
    "                confusion_matrix[1][1] = confusion_matrix[1][1] + 1        #TF\n",
    "        elif test_pre[i] == 1:\n",
    "            confusion_matrix[1][0] = confusion_matrix[1][0] + 1            #FN\n",
    "        else:\n",
    "            confusion_matrix[0][1] = confusion_matrix[0][1] + 1            #FP\n",
    "    return confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mostImportantWords(dic,train_features,length):\n",
    "    lr = linear_model.LogisticRegression(multi_class = 'ovr')\n",
    "    lr.fit(train_features,train_lable)\n",
    "    weight_vector = lr.coef_\n",
    "    sort_index = np.argsort(weight_vector[0])\n",
    "    words_list = []\n",
    "    for i in range(length):\n",
    "        words_list.append(dic.keys()[sort_index[len(sort_index)-1-i]])\n",
    "    return words_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the fist 15 most important words are:  ['absolutel', 'good', 'extra', 'and', 'must', 'functionality', '!', 'away', 'very', 'charge', 'price', 'i', 'highly', 'figure', 'care']\n",
      "1 gram logistic regression score: 0.71500\n",
      "1 gram logistic regression confusion matrix: [[198, 102], [69, 231]]\n"
     ]
    }
   ],
   "source": [
    "# logistic regression 1 gram\n",
    "lr_score,lr_confusion_matrix= lrImplement(train_features,train_lable,test_features,test_lable)\n",
    "lr_words_num = 15\n",
    "lr_words = mostImportantWords(all_dic,train_features,lr_words_num)\n",
    "print \"the fist\",lr_words_num,\"most important words are: \", lr_words\n",
    "print \"1 gram logistic regression score:\",'%6.5f'%lr_score\n",
    "print \"1 gram logistic regression confusion matrix:\",lr_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 gram naive bayes score: 0.64167\n",
      "1 gram naive bayes confusion matrix: [[266, 34], [181, 119]]\n"
     ]
    }
   ],
   "source": [
    "# naive bayes 1 gram\n",
    "gnb_score,gnb_confusion_matrix = gnbImplement(train_features,train_lable,test_features,test_lable)\n",
    "print '1 gram naive bayes score:','%6.5f'%gnb_score\n",
    "print \"1 gram naive bayes confusion matrix:\",gnb_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 2-gram modle\n",
    "def creat2GramDic(DF_train):\n",
    "    DF_dic = {}\n",
    "    for i in range(0,800):\n",
    "        if len(DF_train[i][0]) < 2:\n",
    "            if DF_dic.get(DF_train[i][0][0]) == None:\n",
    "                DF_dic[DF_train[i][0][0]] = 0\n",
    "        else:\n",
    "            for j in range(0,len(DF_train[i][0])-1):\n",
    "                if DF_dic.get(DF_train[i][0][j]+DF_train[i][0][j+1]) == None:\n",
    "                    DF_dic[DF_train[i][0][j]+DF_train[i][0][j+1]] = 0\n",
    "    return DF_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_dic_2g = creat2GramDic(all_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_features_2g = getFeatures(all_test,all_dic_2g,2)\n",
    "train_features_2g = getFeatures(all_train,all_dic_2g,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "normalizeFeatures(test_features_2g)\n",
    "normalizeFeatures(train_features_2g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the fist 15 important words are:  ['sometime', 'toreturn', 'ontelephone', 'letyou', u'iplace', u'expect!', u'thatit', 'undergrey', 'ofall', 'solidkeyboard', u'beperhaps', 'nothappy', 'ofuse', 'atan', 'easyto']\n",
      "2 gram logistic regression score: 0.62500\n",
      "2 gram logistic regression confusion matrix: [[137, 163], [62, 238]]\n"
     ]
    }
   ],
   "source": [
    "# logistic regression 2 gram\n",
    "lr_score_2g,lr_confusion_matrix_2g= lrImplement(train_features_2g,train_lable,test_features_2g,test_lable)\n",
    "lr_words_num_2g = 15\n",
    "lr_words_2g = mostImportantWords(all_dic_2g,train_features,lr_words_num_2g)\n",
    "print \"the fist\",lr_words_num,\"important words are: \", lr_words_2g\n",
    "print \"2 gram logistic regression score:\",'%6.5f'%lr_score_2g\n",
    "print \"2 gram logistic regression confusion matrix:\",lr_confusion_matrix_2g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 gram naive bayes score: 0.64500\n",
      "2 gram naive bayes confusion matrix: [[262, 38], [175, 125]]\n"
     ]
    }
   ],
   "source": [
    "# naive bayes 2 gram\n",
    "gnb_score_2g,gnb_confusion_matrix_2g = gnbImplement(train_features_2g,train_lable,test_features_2g,test_lable)\n",
    "print \"2 gram naive bayes score:\",'%6.5f'%gnb_score_2g\n",
    "print \"2 gram naive bayes confusion matrix:\",gnb_confusion_matrix_2g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#PCA\n",
    "def getAverage(data):\n",
    "    average_train_features = data[0]\n",
    "    for i in range(1,len(data)):\n",
    "        average_train_features = average_train_features + data[i]\n",
    "    average_train_features = average_train_features/sum(average_train_features)\n",
    "    return average_train_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def computeV(data,q):\n",
    "    U,D,Vt = np.linalg.svd(data)\n",
    "    Vq = np.transpose(Vt[0:q])\n",
    "    return Vq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def PCA(data,average,q):\n",
    "    Vq = computeV(data,q)\n",
    "    datanew = copy.deepcopy(data)\n",
    "    for i in range(len(data)):\n",
    "        lamda = np.dot(np.transpose(Vq),(data[i]-average))\n",
    "        datanew[i] = average + np.dot(Vq,lamda)\n",
    "    return datanew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def repetition1GramQ(q):\n",
    "    for qf in q:\n",
    "        train_features_q = PCA(train_features,average_train_features,qf)\n",
    "        test_features_q = PCA(test_features,average_test_features,qf)\n",
    "        normalizeFeatures(test_features_q)\n",
    "        normalizeFeatures(train_features_q)\n",
    "        lr_score_q,lr_confusion_matrix_q= lrImplement(train_features_q,train_lable,test_features_q,test_lable)\n",
    "        lr_words_num_q = 15\n",
    "        lr_words_q = mostImportantWords(all_dic,train_features_q,lr_words_num_q)\n",
    "        print \"the fist\",lr_words_num_q,\"important words are: \", lr_words_q\n",
    "        print \"1 gram logistic regression score:\",'%6.5f'%lr_score_q ,\" with q =\",qf\n",
    "        print \"1 gram logistic regression confusion matrix:\",lr_confusion_matrix_q,\" with q =\",qf\n",
    "        gnb_score_q,gnb_confusion_matrix_q = gnbImplement(train_features_q,train_lable,test_features_q,test_lable)\n",
    "        print \n",
    "        print \"1 gram naive bayes score:\",'%6.5f'%gnb_score_q ,\" with q =\",qf\n",
    "        print \"1 gram naive bayes confusion matrix:\",gnb_confusion_matrix_q,\" with q =\",qf\n",
    "        print '\\n'*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def repetition2GramQ(q):\n",
    "    for qf in q:\n",
    "        train_features_q_2g = PCA(train_features_2g,average_train_features_2g,qf)\n",
    "        test_features_q_2g = PCA(test_features_2g,average_test_features_2g,qf)\n",
    "        normalizeFeatures(test_features_q_2g)\n",
    "        normalizeFeatures(train_features_q_2g)\n",
    "        lr_score_q_2g,lr_confusion_matrix_q_2g= lrImplement(train_features_q_2g,train_lable,test_features_q_2g,test_lable)\n",
    "        lr_words_num_q_2g = 15\n",
    "        lr_words_q_2g = mostImportantWords(all_dic_2g,train_features_q_2g,lr_words_num_q_2g)\n",
    "        print \"the fist\",lr_words_num_q_2g,\"important words are: \", lr_words_q_2g        \n",
    "        print \"2 gram logistic regression score:\",'%6.5f'%lr_score_q_2g ,\" with q =\",qf\n",
    "        print \"2 gram logistic regression confusion matrix:\",lr_confusion_matrix_q_2g,\" with q =\",qf\n",
    "        gnb_score_q_2g,gnb_confusion_matrix_q_2g = gnbImplement(train_features_q_2g,train_lable,test_features_q_2g,test_lable)\n",
    "        print \n",
    "        print \"2 gram naive bayes score:\",'%6.5f'%gnb_score_q_2g ,\" with q =\",qf\n",
    "        print \"2 gram naive bayes confusion matrix:\",gnb_confusion_matrix_q_2g,\" with q =\",qf\n",
    "        print '\\n'*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "average_train_features = getAverage(train_features)\n",
    "average_test_features = getAverage(test_features)\n",
    "average_train_features_2g = getAverage(train_features_2g)\n",
    "average_test_features_2g = getAverage(test_features_2g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the fist 15 important words are:  ['absolutel', 'and', 'good', '!', 'very', 'install', 'excellent', 'too', 'price', 'buyerbe', 'a', 'either', 'value', 'include', 'magical']\n",
      "1 gram logistic regression score: 0.58667  with q = 10\n",
      "1 gram logistic regression confusion matrix: [[138, 162], [86, 214]]  with q = 10\n",
      "\n",
      "1 gram naive bayes score: 0.50000  with q = 10\n",
      "1 gram naive bayes confusion matrix: [[300, 0], [300, 0]]  with q = 10\n",
      "\n",
      "\n",
      "\n",
      "the fist 15 important words are:  ['absolutel', 'good', 'and', 'extra', 'functionality', 'must', '!', 'i', 'very', 'place', 'unit', 'switch', 'price', 'excellent', 'an']\n",
      "1 gram logistic regression score: 0.66667  with q = 50\n",
      "1 gram logistic regression confusion matrix: [[179, 121], [79, 221]]  with q = 50\n",
      "\n",
      "1 gram naive bayes score: 0.54833  with q = 50\n",
      "1 gram naive bayes confusion matrix: [[63, 237], [34, 266]]  with q = 50\n",
      "\n",
      "\n",
      "\n",
      "the fist 15 important words are:  ['absolutel', 'good', 'extra', 'and', 'must', 'functionality', 'away', '!', 'very', 'charge', 'price', 'i', 'highly', 'install', 'figure']\n",
      "1 gram logistic regression score: 0.67500  with q = 100\n",
      "1 gram logistic regression confusion matrix: [[177, 123], [72, 228]]  with q = 100\n",
      "\n",
      "1 gram naive bayes score: 0.52500  with q = 100\n",
      "1 gram naive bayes confusion matrix: [[24, 276], [9, 291]]  with q = 100\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "repetition1GramQ([10,50,100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the fist 15 important words are:  ['whoseear', 'ripby', 'againfor', 'noisecancel', 'andgo', 'best!', 'trulyawful', 'thesame', 'arelative', 'andgreat', 'mostlyit', 'confortableto', 'andcontact', 'fromthem', 'thesound']\n",
      "2 gram logistic regression score: 0.49500  with q = 10\n",
      "2 gram logistic regression confusion matrix: [[264, 36], [267, 33]]  with q = 10\n",
      "\n",
      "2 gram naive bayes score: 0.50000  with q = 10\n",
      "2 gram naive bayes confusion matrix: [[300, 0], [300, 0]]  with q = 10\n",
      "\n",
      "\n",
      "\n",
      "the fist 15 important words are:  ['whoseear', 'ripby', 'andgo', 'shieldbe', 'iwaste', 'thegenuine', 'openthere', 'mostlyit', 'qualitysound', 'againfor', 'ofwarranty', 'willprobably', 'receipti', 'andgreat', 'myfavorite']\n",
      "2 gram logistic regression score: 0.57333  with q = 50\n",
      "2 gram logistic regression confusion matrix: [[107, 193], [63, 237]]  with q = 50\n",
      "\n",
      "2 gram naive bayes score: 0.51500  with q = 50\n",
      "2 gram naive bayes confusion matrix: [[292, 8], [283, 17]]  with q = 50\n",
      "\n",
      "\n",
      "\n",
      "the fist 15 important words are:  ['whoseear', 'thegenuine', 'ripby', 'andgo', 'shieldbe', 'iwaste', 'fromthe', 'ofwarranty', 'qualitysound', 'receipti', 'justsuperb', 'againfor', 'openthere', 'justlove', 'willprobably']\n",
      "2 gram logistic regression score: 0.56667  with q = 100\n",
      "2 gram logistic regression confusion matrix: [[119, 181], [79, 221]]  with q = 100\n",
      "\n",
      "2 gram naive bayes score: 0.50333  with q = 100\n",
      "2 gram naive bayes confusion matrix: [[77, 223], [75, 225]]  with q = 100\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "repetition2GramQ([10,50,100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
